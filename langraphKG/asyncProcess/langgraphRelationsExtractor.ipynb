{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a9ff4db",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbe2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from json_repair import repair_json\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742e3379",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "ollama_base_url = \"\"\n",
    "\n",
    "if os.getenv(\"BASE_URL\"):\n",
    "    ollama_base_url = os.getenv(\"BASE_URL\")\n",
    "else:\n",
    "    ollama_base_url = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7212e6f",
   "metadata": {},
   "source": [
    "### LLM Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc8540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "relations_extractor_llm = \"llama3.1\"\n",
    "relations_json_formatter_llm = \"llama3.1\"\n",
    "summary_llm = \"llama3.1\"\n",
    "summary_json_formatter_llm = \"llama3.1\"\n",
    "name_date_llm = \"llama3.1\"\n",
    "name_date_json_formatter_llm = \"llama3.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445c7c08",
   "metadata": {},
   "source": [
    "### Relationship Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad0c60-3208-48fb-af82-0024630b4da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    base_url=ollama_base_url,\n",
    "    model=relations_extractor_llm,\n",
    "    format=\"json\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "     You are an expert in analyzing financial circulars and extracting key information. Your task is to carefully read the given PDF content from a circular and extract specific details in a structured JSON format. Start extracting relationships after the Title of the document.\n",
    "\n",
    "    Relationships in the context is defined as mention of a particular document, circular, notification, laws, acts. in the current document. Extract the most meaningful single word relationship mentioned in the document. While mentioning the document, please only include the title of the document, date and other identifiers are not required. \n",
    "    \n",
    "    Example of relationships include but are not limited to: superseded, amended, overturned, replaced, etc.\n",
    "\n",
    "    <JSON Output Structure>\n",
    "    \"relations\": {{\n",
    "      \"Document 1\": \"Relationship with current document\",\n",
    "      \"Document 2\": \"Relationship with current document\"\n",
    "    }}\n",
    "    </JSON Structure>\n",
    "\n",
    "    <PDF Page Content>\n",
    "    {pdf_content}\n",
    "    </PDF Page Content>\n",
    "    \"\"\",\n",
    "    input_variables=[\"pdf_content\"],\n",
    ")\n",
    "\n",
    "page_relations_extractor_chain = prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672ac64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    base_url=ollama_base_url,\n",
    "    model=relations_json_formatter_llm,\n",
    "    format=\"json\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Given the Required Output JSON schema, you are required to format by combining individual string output into a single structured JSON format. Remove or Merge any duplicate or redundant information.\n",
    "\n",
    "    <Unformatted Input>\n",
    "    {unformatted_input}\n",
    "    </Unformatted Input>\n",
    "\n",
    "    <Formatted JSON Output Schema>\n",
    "    \"relations\": {{\n",
    "      \"Document 1\": \"Relationship with current document\",\n",
    "      \"Document 2\": \"Relationship with current document\"\n",
    "    }}\n",
    "    </Formatted JSON Output Schema>\n",
    "\n",
    "    \"\"\",\n",
    "    input_variables=[\"pdf_content\"],\n",
    ")\n",
    "\n",
    "relations_json_formatter_chain = prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc45a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = PyPDFLoader('/workspace/legalAgent/langraphKG/data/circulars/Existing Circular.pdf').load()\n",
    "# output = \"\"\n",
    "\n",
    "# for i in range(len(pdf)):\n",
    "#     page_output = page_relations_extractor_chain.invoke({'pdf_content': pdf[i].page_content})\n",
    "#     page_output = str(page_output)\n",
    "#     output += page_output + \"\\n\"\n",
    "\n",
    "# output = relations_json_formatter_chain.invoke({'unformatted_input': output})\n",
    "# output = repair_json(str(output))\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7659202",
   "metadata": {},
   "source": [
    "### Summary Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2be822",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    base_url=ollama_base_url,\n",
    "    model=summary_llm,\n",
    "    format=\"json\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an expert in analyzing financial circulars and extracting key information. Your task is to carefully read the given PDF content from a circular and extract specific details in a structured JSON format. \n",
    "\n",
    "    Summarize the content of the document. The summary should be concise and capture the essence of the document.\n",
    "    \n",
    "\n",
    "    <JSON Output Structure>\n",
    "    \"summary\": \"summary of the document\"\n",
    "    </JSON Structure>\n",
    "\n",
    "    <PDF Page Content>\n",
    "    {pdf_content}\n",
    "    </PDF Page Content>\n",
    "    \"\"\",\n",
    "    input_variables=[\"pdf_content\"],\n",
    ")\n",
    "\n",
    "summary_chain = prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154af035",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    base_url=ollama_base_url,\n",
    "    model=summary_json_formatter_llm,\n",
    "    format=\"json\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Given the Required Output JSON schema, you are required to format by using the page wise summary to generate a single complete summary for the document and format it in JSON format. Remove or Merge any duplicate or redundant information.\n",
    "\n",
    "    <Unformatted Input>\n",
    "    {unformatted_input}\n",
    "    </Unformatted Input>\n",
    "\n",
    "    <Formatted JSON Output Schema>\n",
    "    \"summary\": \"summary of the document\"\n",
    "    </Formatted JSON Output Schema>\n",
    "    \"\"\",\n",
    "    input_variables=[\"pdf_content\"],\n",
    ")\n",
    "\n",
    "summary_json_formatter_chain = prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb14967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = PyPDFLoader('/workspace/fmc/agenticKG/langraphApproach/Existing Circular.pdf').load()\n",
    "# output = \"\"\n",
    "\n",
    "# for i in range(len(pdf)):\n",
    "#     page_output = summary_chain.invoke({'pdf_content': pdf[i].page_content})\n",
    "#     page_output = str(page_output)\n",
    "#     output += page_output + \"\\n\"\n",
    "\n",
    "# output = summary_json_formatter_chain.invoke({'unformatted_input': output})\n",
    "# output = repair_json(str(output))\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41223865",
   "metadata": {},
   "source": [
    "### Name and Date Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7014b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    base_url=ollama_base_url,\n",
    "    model=name_date_llm,\n",
    "    format=\"json\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an expert in analyzing financial circulars and extracting key information. Your task is to carefully read the given PDF content from a circular and extract specific details in a structured JSON format. \n",
    "\n",
    "    1. Name: Provide the name of the document mentioned at the very start not including RBI/Year/No\n",
    "    2. Date of Issue: Find and extract the date when the circular was issued.\n",
    "    \n",
    "    <JSON Output Structure>\n",
    "    \"name\": \"The full name of the document without '/'\",\n",
    "    \"date_of_issue\": \"The date when the circular was issued in DD/MM/YYYY format\",\n",
    "    </JSON Structure>\n",
    "\n",
    "    <PDF Page Content>\n",
    "    {pdf_content}\n",
    "    </PDF Page Content>\n",
    "    \"\"\",\n",
    "    input_variables=[\"pdf_content\"],\n",
    ")\n",
    "\n",
    "name_date_chain = prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630add31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = PyPDFLoader('/workspace/fmc/agenticKG/langraphApproach/Existing Circular.pdf').load()\n",
    "# output = name_date_chain.invoke({'pdf_content': pdf[0].page_content})\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df111309",
   "metadata": {},
   "source": [
    "### State Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e956ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        path: The document path.\n",
    "        name: The name of the document.\n",
    "        date_of_issue: The date when the circular was issued.\n",
    "        summary: The summary of the document.\n",
    "        relations: The relationships between the current document and other documents.\n",
    "    \"\"\"\n",
    "\n",
    "    path: str\n",
    "    name: str\n",
    "    date_of_issue: str\n",
    "    summary: str\n",
    "    relations: List[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e821d56",
   "metadata": {},
   "source": [
    "### Node Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f860894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name_date(state):\n",
    "    \"\"\"\n",
    "    Extract name and date of issue\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New keys added to state, name and date_of_issue, that contain the name and date of issue\n",
    "    \"\"\"\n",
    "    print(\"---EXTRACTING NAME AND DATE---\")\n",
    "    pdf = PyPDFLoader(state[\"path\"]).load()\n",
    "    output = name_date_chain.invoke({\"pdf_content\": pdf[0].page_content})\n",
    "    state[\"name\"] = output[\"name\"].replace(\"/\", \" \")\n",
    "    state[\"date_of_issue\"] = output[\"date_of_issue\"]\n",
    "    return state\n",
    "\n",
    "\n",
    "def extract_relationships(state):\n",
    "    \"\"\"\n",
    "    Extract relationships\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, relations, that contains the relationships between the current document and other documents\n",
    "    \"\"\"\n",
    "    print(\"---EXTRACTING RELATIONSHIPS---\")\n",
    "    pdf = PyPDFLoader(state[\"path\"]).load()\n",
    "    output = \"\"\n",
    "    for i in range(len(pdf)):\n",
    "        page_output = page_relations_extractor_chain.invoke(\n",
    "            {\"pdf_content\": pdf[i].page_content}\n",
    "        )\n",
    "        page_output = str(page_output)\n",
    "        output += page_output + \"\\n\"\n",
    "    output = relations_json_formatter_chain.invoke({\"unformatted_input\": output})\n",
    "    output = repair_json(str(output))\n",
    "    output = json.loads(output)\n",
    "    state[\"relations\"] = output[\"relations\"]\n",
    "    return state\n",
    "\n",
    "\n",
    "def summarize_document(state):\n",
    "    \"\"\"\n",
    "    Summarize the document\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, summary, that contains the summary of the document\n",
    "    \"\"\"\n",
    "    print(\"---SUMMARIZING DOCUMENT---\")\n",
    "    pdf = PyPDFLoader(state[\"path\"]).load()\n",
    "    output = \"\"\n",
    "    for i in range(len(pdf)):\n",
    "        page_output = summary_chain.invoke({\"pdf_content\": pdf[i].page_content})\n",
    "        page_output = str(page_output)\n",
    "        output += page_output + \"\\n\"\n",
    "    output = summary_json_formatter_chain.invoke({\"unformatted_input\": output})\n",
    "    output = repair_json(str(output))\n",
    "    output = json.loads(output)\n",
    "    state[\"summary\"] = output[\"summary\"]\n",
    "    return state\n",
    "\n",
    "\n",
    "def format_output(state):\n",
    "    \"\"\"\n",
    "    Format the output\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): The formatted output\n",
    "    \"\"\"\n",
    "    print(\"---FORMATTING OUTPUT---\")\n",
    "    output = {\n",
    "        \"name\": state[\"name\"],\n",
    "        \"date_of_issue\": state[\"date_of_issue\"],\n",
    "        \"summary\": state[\"summary\"],\n",
    "        \"relations\": state[\"relations\"],\n",
    "    }\n",
    "    output = repair_json(str(output))\n",
    "    output = json.loads(output)\n",
    "\n",
    "    output_path = \"./output/\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    with open(f\"{output_path}{state['name']}.json\", \"w\") as f:\n",
    "        json.dump(output, f)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f0b263",
   "metadata": {},
   "source": [
    "### Graph Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3801a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"name_date\", extract_name_date)\n",
    "workflow.add_node(\"relationships\", extract_relationships)\n",
    "workflow.add_node(\"doc_summary\", summarize_document)\n",
    "workflow.add_node(\"output_formatting\", format_output)\n",
    "\n",
    "workflow.add_edge(START, \"name_date\")\n",
    "workflow.add_edge(\"name_date\", \"relationships\")\n",
    "workflow.add_edge(\"relationships\", \"doc_summary\")\n",
    "workflow.add_edge(\"doc_summary\", \"output_formatting\")\n",
    "workflow.add_edge(\"output_formatting\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb32fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291ee502",
   "metadata": {},
   "source": [
    "### Executing Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64654cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"circulars2/\"\n",
    "for filename in os.listdir(directory_path):\n",
    "    print(f\"Processing {filename}...\")\n",
    "    inputs = {\n",
    "        \"path\": f\"{directory_path}{filename}\",\n",
    "        \"name\": \"\",\n",
    "        \"date_of_issue\": \"\",\n",
    "        \"summary\": \"\",\n",
    "        \"relations\": [],\n",
    "    }\n",
    "    for output in app.stream(inputs):\n",
    "        for key, value in output.items():\n",
    "            print(\"---\" * 5)\n",
    "            print(f\"{key}: {value}\")\n",
    "            print(\"---\" * 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
